\chapter{Methods} \label{chap:method}

The main method used throughout this thesis is ground-state quantum Monte Carlo (QMC). This chapter provides a physically motivated introduction to this method.
In the first part, I start from the familiar finite-temperature classical Monte Carlo method, then describe its generalization to a quantum system, finally take the zero-temperature limit.
The second part of this chapter describes practical methods for constructing a many-body trial wave function, which is a crucial ingredient in many QMC methods.

\section{Classical Monte Carlo}
The Monte Carlo methods mentioned in this thesis perform high-dimensional integrals by using random numbers to sample probability distributions. These distributions must be non-negative in the entire domain of ``states'' over which they are defined. In classical mechanics, a ``state'' of N particles in $3$ dimensions is labeled by the positions $\bs{R}\equiv\{\bs{r}_i\}$ and momenta $\bs{P}\equiv\{\bs{p}_i\}$ of the particles $i=1,\dots,N$. The classical partition function for the canonical ensemble
\begin{align} \label{eq:classical-nvt-part}
Z \equiv \text{Tr}(e^{-H/k_BT}) = \dfrac{1}{N!h^{3N}} \int d^{3N}\bs{R} d^{3N}\bs{p}~e^{-H(\bs{R}, \bs{P})/k_BT},
\end{align}
where $H(\bs{R}, \bs{P})$ is the hamiltonian, $k_B$ is the Boltzmann constant, $h$ is the Planck constant, and $T$ is temperature. For $N$ distinguishable non-relativistic particles with mass $m$, the kinetic contribution $\dfrac{p^2}{2m}$ to eq.~(\ref{eq:classical-nvt-part}) can be integrated analytically, giving
\begin{align}\label{eq:classical-nvt-part-v}
Z = \dfrac{1}{N!\Lambda^{3}} \int d^{3N}\bs{R} e^{-\beta V(\bs{R})},
\end{align}
where $V(\bs{R})$ is the potential energy of the $N$-particle system, $\beta\equiv k_BT$, and $\Lambda$ the de Broglie wavelength
\begin{align} \label{eq:debroglie}
\Lambda = \left(
\dfrac{h^2}{2\pi mk_BT}
\right)^{1/2}.
\end{align}

All equilibrium statistical mechanics properties can be calculated from the partition function, so the entirety of classical equilibrium statistical mechanics reduces to the problem of evaluating the 3N-dimensional integral in eq.~(\ref{eq:classical-nvt-part-v}) and its derivatives. Monte Carlo methods are ideally suited to evaluating high-dimensional integrals, because the amount of computation does not increase as an exponential in the number of dimensions as in a brute-force quadrature approach.

To calculate a property in the canonical ensemble, ones takes the trace
\begin{align}
\braket{O} = \dfrac{\Tr{Oe^{-\beta H}}}{\Tr{e^{-\beta H}}},
\end{align}
where $\braket{}$ denotes ensemble average. Limiting to local observables that can be evaluated on the particle coordinates, e.g., total potential energy $V(\bs{r})$ and pair correlation function $g(r)$
\begin{align} \label{eq:int-obs}
\braket{O} = \int d^{3N}\bs{R} \dfrac{e^{-\beta V(\bs{R})}}{\int d^{3N}\bs{R}' e^{-\beta V(\bs{R}')}} O(\bs{R}) = \int d^{3N}\bs{R} \pi(\bs{R})O(\bs{R}),
\end{align}
where $\pi(\bs{R})$ is the \emph{Bolzmann distribution}
\begin{align} \label{eq:bolzmann-pi}
\pi(\bs{R}) \equiv \dfrac{e^{-\beta V(\bs{r})}}{\int d^{3N}\bs{R}' e^{-\beta V(\bs{R}')}} \propto e^{-\beta V(\bs{R})}.
\end{align}
Monte Carlo estimation of $\braket{O}$ works by sampling particle configurations from the Bolzmann distribution $\pi(\bs{R})$ and accumulating the average $O(\bs{R})$
\begin{align}
\braket{O} = \lim\limits_{N_s\rightarrow\infty} \frac{1}{N_s} \sum\limits_{i=1}^{N_s} O(\bs{R}_i).
\end{align}
How does one sample a generic multi-dimensional probability distribution such as $\pi(\bs{R})$?
An excellent answer was given a 1953 paper authored by Metropolis \textit{et al.}~\cite{Metropolis1953}. The Metropolis algorithm, designed by the Rosenbluths supervised by the Tellers, works by constructing a Markov chain having $\pi(\bs{R})$ as its stationary state. This is achieved by a rejection method that maintains detailed balance
\begin{align} \label{eq:detailed-balance}
\pi(\bs{R})P(\bs{R}\rightarrow\bs{R}')=\pi(\bs{R}')P(\bs{R}'\rightarrow\bs{R}),
\end{align}
where $P(\bs{R}\rightarrow\bs{R}')$ is the Markov chain transition probability from state $\bs{R}$ to $\bs{R}'$. The Metropolis algorithm breaks $P$ into two steps: proposal and acceptance
\begin{align} \label{eq:metropolis-prob}
P(\bs{R}\rightarrow\bs{R}') = T(\bs{R}\rightarrow\bs{R}')A(\bs{R}\rightarrow\bs{R}'),
\end{align}
with the following accept/reject criteria: For any transition probability used to propose the state change $T(\bs{R}\rightarrow\bs{R}')$, accept the change with probability
\begin{align} \label{eq:metropolis-accept}
A(\bs{R}\rightarrow\bs{R}') = \min\left(1, \dfrac{\pi(\bs{R}')T(\bs{R}'\rightarrow\bs{R})}{\pi(\bs{R})T(\bs{R}\rightarrow\bs{R}')}\right).
\end{align}
Using eq.~(\ref{eq:metropolis-prob}) and (\ref{eq:metropolis-accept}) to prove eq.~(\ref{eq:detailed-balance}) is a good way to appreciate the design of this acceptance probability.

Mathematically, $\pi(\bs{R})$ is the unique stationary state of the Markov chain constructed by the Metropolis method so long as $P(\bs{R}\rightarrow\bs{R}')$ is ergodic. That is, there is finite probability of reaching any state $\bs{R}'$ starting from any state $\bs{R}$ using the transition rule $P$.
In practice, however, a simulation can be stuck in a meta-stable state for its entire duration, for example, due to a bad initial condition. Careful monitoring and checking of convergence is a must in any serious Monte Carlo simulation.

\section{Quantum Monte Carlo}

%A typical introduction to quantum Monte Carlo (QMC) starts with the oldest and simplest method variation Monte Carlo (VMC), then work its way to diffusion Monte Carlo (DMC) and path integral Monte Carlo.
I will start with the general, albeit somewhat complicated, path integral Monte Carlo (PIMC) method, because it rigorously takes temperature into account and connects well with classical Monte Carlo. Then, I will describe ground-state methods as limits and efficiency tricks to specialize the path integral method to the ground state. While contrary to the historic progression of these methods, I find this perspective helpful for relating the methods and visualizing them in their respective niches.

\subsection{Path Integral Monte Carlo} \label{sec:method-pimc}
The quantum partition function for the canonical ensemble needs to trace over discrete N-particle eigenstates, rather than 2N 3-dimensional variables as in eq.~(\ref{eq:classical-nvt-part})
\begin{align}
Z\equiv \text{Tr}(e^{-\hat{H}/k_BT})=\text{Tr}\left(
\sum\limits_{i=1}^{\infty} e^{-E_i/k_BT}\ket{\Psi_i}\bra{\Psi_i}
\right),
\end{align}
where $E_i$ and $\ket{\Psi_i}$ are the eigenvalues and eigenstates of the hamiltonian $H$. To make contact with classical mechanics, we put the density matrix (DM) for distinguishable particles in position basis (first quantization)
\begin{align}
\rho_D(\bs{R}, \bs{R}'; \beta) \equiv \braket{\bs{R}|e^{-\beta H}|\bs{R}'},
\end{align}
where $\beta\equiv \frac{1}{k_B T}$. 
Then the partition function becomes
\begin{align} \label{eq:quantum-nvt-zd}
Z(\beta) = \int d^{3N}\bs{R} \rho_D(\bs{R},\bs{R};\beta),
\end{align}
which can be exactly factorized into two pieces
\begin{align}
Z(\beta) = \int d^{3N}\bs{R}d^{3N}\bs{R}' \rho_D(\bs{R},\bs{R}';\tau)\rho_D(\bs{R}',\bs{R};\beta-\tau).
\end{align}
This factorization can be repeated until the temperature becomes high enough ($\tau\rightarrow0$) that a semi-classical approximation to $\rho_D(\bs{R},\bs{R}';\tau)$ is accurate. Given translation symmetry along imaginary time, $\beta$ is typically broken down into $M$ equal-length pieces, i.e., $\tau=\beta/M$.
For $N$ non-relativistic particles each having mass $m$, $\rho_D$ can be calculated as an integral over a discretized \textit{path} of particle coordinates $\{\bs{R}_m\}$
\begin{align} \label{eq:pimc-rhod}
\rho_D(\bs{R}_0,\bs{R}_M;\beta) = \lim\limits_{M\rightarrow\infty} \int d\bs{R}_1\dots d\bs{R}_{M-1}\exp\left(\sum\limits_{m=1}^M \ln \rho_D^p(\bs{R}_{m-1},\bs{R}_m) \right).
\end{align}
The \emph{primitive approximation} for the high-temperature density matrix $\rho_D^p$ satisfies
\begin{align} \label{eq:pimc-rho-prim}
\dfrac{dN}{2}\ln(4\pi\lambda\tau)-\ln \rho_D^p(\bs{R}_m-1, \bs{R}_m) = \dfrac{(\bs{R}_{m-1}-\bs{R}_m)^2}{4\lambda\tau} + \tau V(\bs{R}_m),
\end{align}
where $\lambda\equiv\dfrac{\hbar^2}{2m}$ is the \emph{quantumness} of the particle and $d$ is the number of spatial dimensions. Thus,
\begin{align}
\rho_D(\bs{R}_0,\bs{R}_M;\beta) = \lim\limits_{M\rightarrow\infty} (4\pi\lambda\tau)^{-dNM/2}\exp\left(
-\sum\limits_{m=1}^M \left[
\dfrac{(\bs{R}_{m-1}-\bs{R}_m)^2}{4\lambda\tau} + \tau V(\bs{R}_m)
\right]
\right).
\end{align}
The main advantage of eq.~(\ref{eq:pimc-rhod}) is that it turns the partition function eq.~(\ref{eq:quantum-nvt-zd}) into an integral of a product of high-temperature DMs over all closed paths
\begin{align} \label{eq:quantum-nvt-zd-pi}
Z=\lim\limits_{M\rightarrow\infty} \int d\bs{R} d\bs{R}_1\dots d\bs{R}_{M-1}
\rho_D(\bs{R},\bs{R}_1;\tau)\rho_D(\bs{R}_1,\bs{R}_2;\tau)\dots\rho_D(\bs{R}_{M-1},\bs{R};\tau).
\end{align}
Each closed path can be visualized as a collection of ring polymers, one for each particle. The linear extension of a ring polymer is proportional to the particle's de Broglie wavelength $\Lambda=\sqrt{4\pi\lambda\beta}$ eq.~(\ref{eq:debroglie}).
For distinguishable particles, the integral needed to evaluate the quantum partition function eq.~(\ref{eq:quantum-nvt-zd-pi}) poses no essential difficulty to a Monte Carlo method when compared with its classical counterpart eq.~(\ref{eq:classical-nvt-part-v}).
One simply has to integrate $M$ classical systems, which are coupled by the spring-like kinetic energy term in eq.~(\ref{eq:pimc-rho-prim}).
Each classical system is typically referred to as a \emph{slice} of imaginary time or a \emph{bead} on the ring polymer.
Converged results is obtained in the zero time step $\tau\rightarrow0$, equivalently the infinite slice $M\rightarrow\infty$ limit.
The the primitive approximation eq.~(\ref{eq:pimc-rho-prim}) to the exact density matrix is correct only to $O(\tau)$, so a large number of beads is needed, resulting in slow simulations.
Better approximations can be constructed to be correct to $O(\tau^2)$, for example the pair-product form in Ref.~\cite{Ceperley1995}.
% a technical difficult for bosons -> permutation moves
However, if the particles are identical bosons, then one has to consider particle permutations along the path (fermions pose an additional essential problem, see Sec.~\ref{sec:fermion-sign-problem})
\begin{align}
\rho_B(\bs{R}_0,\bs{R}_M;\beta) = \frac{1}{N!}\sum\limits_{\mathcal{P}} \rho_D(\bs{R}_0, \mathcal{P}\bs{R}_M;\beta),
\end{align}
where $\mathcal{P}\bs{R}_M$ contains the same $N$ coordinates as $\bs{R}_M$, but with the particles relabeled. This permutation can happen via any number of 1-, 2-, and up to $N$-particle exchanges between adjacent time slices along the path. Thus, the state space of bosonic path integral is much larger than that of boltzmannic path integral. Efficient sampling of permuting paths is a significant technical challenge. Fortunately, no uncontrolled approximation has been introduced and exact simulations are possible for both bolzmannons and bosons via the Monte Carlo method~\cite{Ceperley1995,Meldgin2016}.

\subsection{Variation Path Integral a.k.a. Reptation Monte Carlo}
% ground-state path integral (VPI) -> RMC
% i.e. use a trial wavefunction as link action
Even with accurate approximation to the high-temperature density matrix, the ground state is still costly to study using the path integral formalism presented so far, because a large number of time slices have to be included to approximate $\beta\rightarrow\infty$. Fortunately, one can still efficiently study this zero-temperature limit with the help of a trial wave function $\ket{\Psi_T}$, so long as it is non-negative. The ground-state ``partition'' function has only one term
\begin{align}
Z_0 = \lim\limits_{\beta\rightarrow\infty} \braket{\Psi_0|e^{-\beta H}|\Psi_0},
\end{align}
where $\ket{\Psi_0}$ is the ground state of the hamiltonian $H$.
For sufficiently large $\beta$, any trial wave function not orthogonal to the ground state $\braket{\Psi_T|\Psi_0}\neq0$ will be projected to the ground state by $e^{-\beta H}$, so
\begin{align} \label{eq:rmc-z0}
Z_0 = \lim\limits_{\beta\rightarrow\infty}\braket{\Psi_T|e^{-\frac{\beta}{2} H}e^{-\frac{\beta}{2} H}|\Psi_T} \approx \braket{\Psi_T|e^{-\beta_e H}e^{-\beta_e H}|\Psi_T},
\end{align}
for some $\beta_e$ large enough to be considered ``equilibrated''. Performing path discretization as before
\begin{align} \label{eq:pimc-vpi-z0}
Z_0 = \lim\limits_{M\rightarrow\infty} \int d\bs{R}_{-M}\dots d\bs{R}_0\dots d\bs{R}_{M}
\Psi_T^*(\bs{R}_{-M})\rho(\bs{R}_{-M},\bs{R}_{-M+1};\tau)\dots\rho(\bs{R}_{M-1},\bs{R}_M;\tau)\Psi_T(\bs{R}_M),
\end{align}
where $\tau=\beta_e/M$. $\beta_e$ can be small if $\ket{\Psi_T}$ is a good approximate to the ground state $\ket{\Psi_0}$. In this sense, $\ket{\Psi_T}\bra{\Psi_T}$ plays the role of a low-temperature density matrix to quickly close a long path, although its temperature is ill-defined.
No permutation needs to be sampled because quantum statistics are encoded in the trial wave function.
However, translation symmetry along imaginary time is broken. The $2M+1$ time slices each sample a different probability distribution.
Observables that do not commute with the hamiltonian are unbiased only when evaluated in the middle section $\bs{R}_m$, where $\vert m\vert$ is small.
This is because $\bs{R}_m$ needs to be sufficiently separated from the trail wave function slices $\bs{R}_{-M}$ and $\bs{R}_M$ to be considered the zero-temperature limit.
The trial wave functions at the ends and the DMs in the middle of eq.~(\ref{eq:pimc-vpi-z0}) must all be non-negative for the integrand to be interpreted as a probability distribution for the path $\{\bs{R}_{-M},\dots,\bs{R}_M\}$.
This path is open in general ($\bs{R}_{-M}\neq\bs{R}_M$) and can be visualized as a ``reptile''. This method was first mentioned as variational path integral (VPI)~\cite{Ceperley1995}, but later popularized as reptation Monte Carlo (RMC)~\cite{Baroni1999}.
While the RMC method can be efficient, it still requires all $M$ classical systems to be stored in memory at one time and intelligent Monte Carlo moves to change the reptile without ergodicity problems. This makes RMC more troublesome to implement than classical Monte Carlo or molecular dynamics, because the entire reptile, containing $O(M)$ classical systems have to be updated to generate $O(1)$ new decorrelated sample for the pure estimator eq.~(\ref{eq:dmc-opure}).

\subsection{Diffusion Monte Carlo} \label{sec:method-dmc}
The diffusion Monte Carlo (DMC) method can be viewed as a simplification of RMC.
When calculating a ground-state observable using eq.~(\ref{eq:rmc-z0}), the \emph{pure estimator}
\begin{align} \label{eq:dmc-opure}
\braket{\hat{O}}_p \equiv \braket{\Psi_T|e^{-\beta_e H}\hat{O}e^{-\beta_e H}|\Psi_T} \approx \braket{\Psi_0|\hat{O}|\Psi_0}
\end{align}
is an unbiased ground-state estimate of $\hat{O}$ whether it commutes with the hamiltonian or not. We can forgo the pure estimator for a simpler algorithm. Consider the \emph{mixed estimator}
\begin{align} \label{eq:dmc-omixed}
\braket{\hat{O}}_m \equiv \braket{\Psi_T|\hat{O}e^{-\beta_e H}|\Psi_T}\approx\braket{\Psi_T|\hat{O}|\Psi_0}.
\end{align}
Equation~(\ref{eq:dmc-omixed}) has the advantage that the operator can be immediately applied to a trial wave function, which is known at the beginning of the calculation. Further, the $\Psi_0$ on the r.h.s. can be interpreted as being propagated from $\Psi_T$ using the \emph{imaginary-time propagator}
\begin{align}
\hat{U}(t) = e^{-t H}.
\end{align}
For any $t>\beta_e$, the mean of the observable eq.~(\ref{eq:dmc-omixed}) should be stationary. The algorithm as described so far is similar to classical molecular dynamics. One starts with a trial wave function at $t=0$ and propagates it along imaginary time. After some initial equilibration period, the mixed estimator fluctuates around some stationary mean. One then runs for ``longer'' and accumulate statistics.

%For non-relativistic particles, $\nabla^2$ in the kinetic energy operator turns into a Green function for diffusion $e^{-t\nabla^2}$.
For identical non-relativistic particles having mass $m$, $\hat{U}$ in coordinate basis is the Green function for imaginary-time Schr\"odinger equation
\begin{align}
G(\bs{R}'\leftarrow\bs{R};t) = \braket{\bs{R}'|\hat{U}(t)|\bs{R}} =  \braket{\bs{R}'|e^{-t(\lambda \nabla^2+V)}|\bs{R}}\nonumber \\ \lim\limits_{\tau\rightarrow 0} G(\bs{R}'\leftarrow\bs{R};\tau) =
\left(
(4\pi\lambda\tau)^{-dN/2}e^{-\dfrac{(\bs{R}-\bs{R}')^2}{4\lambda\tau}}
\right)
\left(
e^{-\tau V(\bs{R})}
\right). \label{eq:dmc-green}
\end{align}
The two terms in eq.~(\ref{eq:dmc-green}) are the Green function for diffusion and weight accumulation.
The quantumness $\lambda=\frac{\hbar^2}{2m}$ of the particle determines its diffusion constant in imaginary time. Lighter particles diffuse ``faster''. One can, in principle, start with any classical system $\bs{R}$, apply the Green functions repeatedly to update $\bs{R}$, and eventually end up sampling the mixed distribution $\braket{\Psi_T|\Psi_0}$.

While eq.~(\ref{eq:dmc-omixed})-(\ref{eq:dmc-green}) contain the main idea behind the DMC method, they do not result in a practical algorithm. The weight of the classical system due to the potential term goes to zero or infinity exponentially fast, especially when two charged particles coalesce. For a stable algorithm, one can modify the Green function eq.~(\ref{eq:dmc-green}) to more directly sample the mixed distribution
\begin{align}
f(\bs{R},t) \equiv \Psi_T^*(\bs{R}) e^{-t(H-E_T)}\Psi_T(\bs{R}) \underset{t\rightarrow\infty}{=} \Psi_T^*(\bs{R})\Psi_0(\bs{R}),
\end{align}
where a trial energy $E_T$ is introduced to stablize the potential term.
Substitute $\Psi_T^{-1}f$ in place of $\Psi$ into the imaginary-time Schr\"odinger equation $-\partial_t \Psi = H\Psi$, where $H=-\lambda\nabla^2+V$, we obtain
\begin{align} \label{eq:dmc-dfdt}
-\partial_t f = \Psi_T H \Psi_T^{-1} f \Rightarrow -\partial_t f=-\lambda\bs{\nabla}\cdot(\bs{\nabla}-\bs{v})f+(E_L-E_T)f,
\end{align}
% derivation is tricky! Remember \nabla\cdot(f\nabla\psi/\psi)
where the local energy $E_L\equiv \dfrac{H\Psi_T}{\Psi_T}$ and the drift vector
\begin{align} \label{eq:dmc-drift}
\bs{v}\equiv2\Psi_T^{-1}\bs{\nabla}\Psi_T=\bs{\nabla}\ln\Psi_T^2.
\end{align}
After this \emph{importance-sampling transformation}, the Green function eq.~(\ref{eq:dmc-green}) is now modified to have three contributing processes: diffusion, drift, and weighting. The pure diffusion process becomes a drift-diffusion process guided by the trial wave function. Further, the weighting by the bare potential energy becomes weighting by the local energy. Given suitably designed trial wave function, $E_L$ can be made continuous even if the original potential $V$ contains divergences, e.g., in the coulomb interaction.
In practice, the mixed distribution is approximated by an ensemble of walkers
\begin{align}
f(\bs{R},t) \approx \sum\limits_{m=1}^{N_w} \delta(\bs{R}-\bs{R}_m),
\end{align}
and the trial energy $E_T$ is adjusted every so often to keep the population of walkers $N_w$ from explosion and extinction. Equation~(\ref{eq:dmc-dfdt}) defines the DMC algorithm.
While not strictly necessary, one typically adds a Metropolis rejection step using the Green function $G$ as transition probability $T$ in eq.~(\ref{eq:metropolis-accept}). This ensures that the algorithm samples the desired probability distribution at any finite time step, where the Green function is approximate~\cite{Reynolds1982}.
%When viewed in a vacuum, the DMC method can be derived simply as a stochastic implementation of the power method in linear algebra.

For bosons and Bolzmannons, DMC gives the exact ground-state energy of $H$ in the limit of infinitesimal time step and uncontrolled walker population. Observables that do not commute with the hamiltonian will suffer a mixed-estimator error, which vanishes as the trial wave function approaches the ground state.

\subsection{Variational Monte Carlo}
Variational Monte Carlo (VMC) can be viewed as a limit of DMC at zero projection time, i.e., no branching. I define VMC as a Monte Carlo algorithm that calculates the expectation value of an operator using a fixed trial wave function $\Psi_T$
\begin{align} \label{eq:vmc}
\braket{\hat{O}} = \braket{\Psi_T|\hat{O}|\Psi_T}.
\end{align}
When VMC is used to calculate the expectation value of the hamiltonian ($\hat{O}=\hat{\ham}$), the resultant energy is an upper bound to the true ground-state energy by the variational principle
\begin{align} \label{eq:wf-variational}
E_V\equiv \braket{\Psi_T|\hat{\ham}|\Psi_T} = \braket{\Psi_T|E_L(\bs{R};\Psi_T)|\Psi_T} \ge E_0,
\end{align}
where the local energy serves as a local estimator for the total energy
\begin{align} \label{eq:wf-eloc}
E_L(\bs{R};\Psi_T) \equiv \dfrac{\ham\Psi_T}{\Psi_T} (\bs{R}).
\end{align}
The variational energy $E_V$ is often taken as a measure of the quality of the trial wave function.
In \emph{variational optimization}, one changes parameters in $\Psi_T$ to lower $E_V$.
However, $E_V$ is only one number and is far from a complete descriptor of the 3N-dimensional many-body wave function.
Another, arguably more powerful, measure of the quality of $\Psi_T$ is the variance of the local energy eq.~(\ref{eq:wf-eloc})
\begin{align}
\sigma^2[\Psi_T] \equiv \braket{\Psi_T|(E_L(\bs{R};\Psi_T)-E_V)^2|\Psi_T}\ge 0.
\end{align}
This variance will be zero if $\Psi_T$ is any eigenstate of $\ham$. Further, for systems with a gap $E_g$, $\sigma^2$ and $E_V$ also provide a lower bound for the ground-state energy by eq.~(6.16) in Ref.~\cite{Martin2016}
\begin{align}
E_V-\sigma^2/E_g \le E_0 \le E_T.
\end{align}

The VMC algorithm is particularly simple for a local observable. In this case, eq.~(\ref{eq:vmc}) becomes an integral over the $3N$-dimensional particle coordinates
\begin{align}
\braket{O} = \int d\bs{r} \dfrac{O(\bs{r})\vert\Psi_T(\bs{r})\vert^2}{\braket{\Psi_T|\Psi_T}},
\end{align}
which is easily evaluated by sampling $\bs{r}$ from the probability distribution
\begin{align}
P(\bs{r}) = \dfrac{\vert\Psi_T(\bs{r})\vert^2}{\braket{\Psi_T|\Psi_T}},
\end{align}
and accumulating $O(\bs{r})$. How does one sample a generic probability distribution like $P(\bs{r})$? One can use the Metropolis algorithm to devise a Markov chain with $P(\bs{r})$ being the stationary distribution. Alternatively, $P(\bs{r})$ can be set to be the stationary distribution of a dynamical process, e.g., Fokker-Planck dynamics~\cite{Hammond1994}.

Suppose we wish a drift-diffusion process governed by
\begin{align} \label{eq:vmc-fokker-planck}
\dfrac{\partial f}{\partial t} = \sum\limits_{i=1}^N \lambda\dfrac{\partial}{\partial\bs{x}_i}\left(
\dfrac{\partial}{\partial\bs{x}_i} -\bs{v}_i(\bs{r})
\right)f
\end{align}
to have $P(\bs{r})$ as its stationary distribution
\begin{align}
\lim\limits_{t\rightarrow\infty} f(\bs{r},t) = P(\bs{r}) \propto \vert\Psi_T\vert^2.
\end{align}
We can set each term in sum of the r.h.s. of eq.~(\ref{eq:vmc-fokker-planck}) to vanish
\begin{align}
\nabla_i^2 P = P\bs{\nabla}_i\cdot\bs{v}_i + \bs{v}_i\cdot\bs{\nabla}_iP,
\end{align}
which gives the drift vector
\begin{align} \label{eq:vmc-drift}
\bs{v}_i = \dfrac{\bs{\nabla}_if}{f} = 2\dfrac{\bs{\nabla}_i\Psi_T}{\Psi_T}.
\end{align}
$\bs{v}$ pushes a walker towards peaks of $P(\bs{r})$, making the sampling process more efficient than a random move.
In fact, no accept/reject procedure is necessary.
The correct stationary distribution $P(\bs{r})$ will be reached so long as the time step is small enough to accurately approximate the Green function for each step.
%The Green function for the Fokker-Planck dynamics eq.~(\ref{eq:vmc-fokker-planck}) governs a drift-diffusion process.
The Langevin equation needed to solve eq.~(\ref{eq:vmc-fokker-planck}) is
\begin{align}
\dfrac{\partial\bs{r}(t)}{\partial t} = \lambda \bs{v}(\bs{r}(t)) + \bs{\eta},
\end{align}
where $\bs{\eta}$ is a multidimensional Gaussian with a mean of zero and a variance of $2\lambda$. In this light, the VMC algorithm is more akin to stochastic classical molecular dynamics than Monte Carlo. However, the most efficient algorithm is obtained when the Fokker-Planck formulation is combined with Metropolis Monte Carlo. By introducing a metropolis accept/reject procedure at each step of the Fokker-Planck dynamics, we eliminate the time step bias because detailed balance is enforced to sample $\vert\Psi_T\vert^2$. Another way to view this is that Fokker-Planck dynamics provides efficient drift-diffusion moves for an exact Monte Carlo method.

Equation~(\ref{eq:vmc-fokker-planck}) defines an efficient implementation of the VMC algorithm. Interestingly, the governing equation of DMC eq.~(\ref{eq:dmc-dfdt}) without the branching term is identical to that of VMC eq.~(\ref{eq:vmc-fokker-planck}) when the same trial wave function is used for drift eq.~(\ref{eq:vmc-drift}).
This implies that the drift-diffusion term in the DMC Green function performs sampling of the trial wave function only. The local energy term in eq.~(\ref{eq:dmc-dfdt}), when accumulated over the drift-diffusion process, is responsible for imaginary-time projection.
%Variational Monte Carlo is the bread and butter of QMC methods.

\subsection{Fermion Sign Problem} \label{sec:fermion-sign-problem}
% sign problem for fermions
An essential difficult arises when one applies the path integral formalism to fermions. Even- and odd-permutations contribute to the fermion DM with opposite signs
\begin{align}
\rho_F(\bs{r}_0,\bs{r}_M;\beta) = \frac{1}{N!}\sum\limits_{\mathcal{P}} (-1)^{\mathcal{P}} \rho_D(\bs{r}_0, \mathcal{P}\bs{r}_M;\beta).
\end{align}
$\rho_F$ is no longer positive definite and cannot be interpreted as a probability distribution to be sampled by Monte Carlo. The canonical workaround is to sample the absolute value of the fermionic DM, which is the bosonic DM, and keep the sign as an observable. In this way, a fermionic observable is calculated as the ratio between a signful bosonic observable and the bosonic average of the permutation sign
\begin{align} \label{eq:pimc-of}
\braket{\hat{O}}_F \equiv \dfrac{\Tr{\hat{O}e^{-\beta H}}_F}{\Tr{e^{-\beta H}}_F}=
\dfrac{\Tr{\hat{O}\hat{\sigma}e^{-\beta H}}_B}{\Tr{\hat{\sigma} e^{-\beta H}}_B}=
\dfrac{\Tr{\hat{O}\hat{\sigma}e^{-\beta H}}_B/Z_B}{\Tr{\hat{\sigma} e^{-\beta H}}_B/Z_B}=\dfrac{\braket{\hat{O}\hat{\sigma}}_B}{ \braket{\hat{\sigma}}_B }.
\end{align}
While mathematically exact, this leads to the well-known \emph{fermion sign problem}, where the denominator in eq.~(\ref{eq:pimc-of}), the average sign, goes to zero exponentially fast as system size $N$ and inverse temperature $\beta$ increase.
To see this, consider the total free energies of $N$ bosons vs. $N$ fermions governed by the same hamiltonian $H$. The average sign can be written as an exponential of the free energy difference
\begin{align} \label{eq:pimc-avg-sign}
\braket{\hat{\sigma}}_B = \dfrac{Z_F}{Z_B} = \dfrac{e^{-\beta F_F}}{e^{-\beta F_B}} = e^{-\beta (F_F-F_B)}.
\end{align}
Since the total free energy is extensive, the exponent in eq.~(\ref{eq:pimc-avg-sign}) is proportional to $\beta N$.
At zero Kelvin, all permutations are equally likely and the average sign is exactly zero.
At the degeneracy temperature and above, \textit{signful} PIMC is often possible, but comes at a hefty computational cost even for very small systems, e.g., $O(10)$ particles.
A practical workaround for the sign problem in path integral is the restricted path approximation~\cite{Ceperley1991,Ceperley1992,Ceperley1996}.
This approximation uses a trial density matrix to restrict the space of paths that can be sampled.
Any Monte Carlo move that constructs a path which crosses the node of the trial density matrix is rejected.
This restricted path integral Monte Carlo (RPIMC) method was proved to be exact if the node of the trial density matrix is exact~\cite{Ceperley1992}.

The sign problem manifests rather differently in DMC than it does in PIMC.
If one runs the bosonic DMC algorithm eq.~(\ref{eq:dmc-dfdt}) using the absolute value of a fermionic trial wave function $\vert\Psi_T\vert$ as guiding function, then the drift vector eq.~(\ref{eq:dmc-drift}) will diverge as a walker approaches the node of $\Psi_T$, pushing the walker away.
This trapping effect greatly diminishes the chance that a walker can cross the node.
Thus, the walker distribution will approach the bosonic solution in this positive nodal pocket.
However, once a walker does cross the node, it quickly gets pushed to regions with high $\vert\Psi_T\vert^2$ and branches to solve a similar bosonic problem in the newly found negative nodal pocket.
Walkers in the positive nodal pocket contribute to estimators with a positive sign, whereas walkers in the negative pocket contribute with a negative sign.
While the final average is the exact fermionic estimator, it is the difference between two large values and its noise diverges exponentially fast with system size and projection time.
Exact fermionic simulation is possible using the release-node method~\cite{Ceperley1978}, but a highly-accurate trial wavefunction is required and much care must be taken to efficiently converge the calculation before noise takes over.

The practical workaround for the sign problem in DMC is the \textit{fixed-node approximation} (for real-valued wave functions).
In this approximation, no walker is allowed to cross the node of the trial wave function.
This effectively adds to the hamiltonian an infinite potential barrier at the node of $\Psi_T$.
The bosonic problem is exactly solved in the nodal pocket within this barrier, while the rest of Hilbert space is constructed via antisymmetry of the wave function.
This restricted random walk effectively constructs a \emph{fixed-node wave function} $\Psi_{FN}$ as an approximation to the true ground state, so the fixed-node DMC (FN-DMC) total energy is variational $E_{FN}\ge E_0$.
The exact ground-state energy can be obtained if the node of the trial wave function is exact.
When generalized to systems with complex-valued trial wave function, an analogous work around is the fixed-phase DMC method (FP-DMC), which forbids walkers to move past phase-change boundaries of the trial wave function.
FP-DMC is so similar to FN-DMC that they are often not distinguished as different methods in the literature.

For a general fermionic system, the sign problem is present in all known QMC methods in some form.
However, the sign problem can be absent in a particular system, for example due to particle-hole symmetry in a half-filled Hubbard model, and can be alleviated at finite-temperature.
Unfortunately, no known polynomial-scaling algorithm can solve the sign problem in all cases.