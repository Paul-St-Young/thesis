\section{Classical Monte Carlo}
The Monte Carlo methods mentioned in this thesis perform high-dimensional integrals by using random numbers to sample probability distributions. These distributions must be non-negative in the entire domain of ``states'' over which they are defined. In Classical mechanics, a ``state'' of N particles is labeled by the positions $\bs{r}\equiv\{\bs{r}_i\}$ and momenta $\bs{p}\equiv\{\bs{p}_i\}$ of the particles $i=1,\dots,N$. The Classical partition function for the canonical ensemble
\begin{align} \label{eq:classical-nvt-part}
Z \equiv \text{Tr}(e^{-H/k_BT}) = \dfrac{1}{N!h^{3N}} \int d\bs{r} d\bs{p} e^{-H(\bs{r}, \bs{p})/k_BT},
\end{align}
where $H(\bs{r}, \bs{p})$ is the hamiltonian, $k_B$ is the Boltzmann constant, $h$ is the Plank constant, and $T$ is temperature. For $N$ distinguishable non-relativistic particles with mass $m$, the kinetic contribution $\dfrac{p^2}{2m}$ to eq.~(\ref{eq:classical-nvt-part}) can be integrated analytically, giving
\begin{align}\label{eq:classical-nvt-part-v}
Z = \dfrac{1}{N!\Lambda^{3}} \int d\bs{r} e^{-\beta V(\bs{r})},
\end{align}
where $V(\bs{r})$ is the potential energy of the system, $\beta\equiv k_BT$, and $\Lambda$ the de Broglie wavelength
\begin{align} \label{eq:debroglie}
\Lambda = \left(
\dfrac{h^2}{2\pi mk_BT}
\right)^{1/2}.
\end{align}

All equilibrium statistical mechanics properties can be calculated from the partition function, so the entirety of Classical equilibrium statistical mechanics reduces to the problem of evaluating the 3N-dimensional integral in eq.~(\ref{eq:classical-nvt-part-v}) and its derivatives. Monte Carlo methods are ideally suited to evaluating high-dimensional integrals, because the amount of computation increases as a polynomial of the number of dimensions rather than as an exponential in a brute-force quadrature approach.

To calculate a property in the canonical ensemble, ones takes the trace
\begin{align}
\braket{O} = \dfrac{\Tr{Oe^{-\beta H}}}{\Tr{e^{-\beta H}}},
\end{align}
where $\braket{}$ denotes ensemble average. Limiting to local observables that can be evaluated on the particle coordinates, e.g., total potential energy $V(\bs{r})$ and pair correlation function $g(r)$
\begin{align}
\braket{O} = \int d\bs{r} \dfrac{e^{-\beta V(\bs{r})}}{\int d\bs{r}' e^{-\beta V(\bs{r}')}} O(\bs{r}) = \int d\bs{r} \pi(\bs{r})O(\bs{r}),
\end{align}
where $\pi(\bs{r})$ is the Bolzmann distribution
\begin{align}
\pi(\bs{r}) \equiv \dfrac{e^{-\beta V(\bs{r})}}{\int d\bs{r}' e^{-\beta V(\bs{r}')}} \propto e^{-\beta V(\bs{r})}.
\end{align}
How does one sample a generic probability distribution such as $\pi(\bs{r})$?
An excellent answer was given a 1953 paper authored by N. Metropolis. The Metropolis algorithm was worked out by the Rosenbluths, who were supervised by the Tellers. It works by constructing a Markov chain having $\pi(\bs{r})$ as its stationary state. This is achieved by a rejection method that maintains detailed balance
\begin{align} \label{eq:detailed-balance}
\pi(\bs{r})P(\bs{r}\rightarrow\bs{r}')=\pi(\bs{r}')P(\bs{r}'\rightarrow\bs{r}),
\end{align}
where $P(\bs{r}\rightarrow\bs{r}')$ is the Markov chain transition probability from state $\bs{r}$ to $\bs{r}'$. The Metropolis algorithm breaks $P$ into two steps: proposal and acceptance
\begin{align} \label{eq:metropolis-prob}
P(\bs{r}\rightarrow\bs{r}') = T(\bs{r}\rightarrow\bs{r}')A(\bs{r}\rightarrow\bs{r}'),
\end{align}
with the following acceptance/rejection criteria: For any transition probability used to propose the state change $T(\bs{r}\rightarrow\bs{r}')$, accept the change with probability
\begin{align} \label{eq:metropolis-accept}
A(\bs{r}\rightarrow\bs{r}') = \min\left(1, \dfrac{\pi(\bs{r})T(\bs{r}\rightarrow\bs{r}')}{\pi(\bs{r}')T(\bs{r}'\rightarrow\bs{r})}\right).
\end{align}
Using eq.~(\ref{eq:metropolis-prob}) and (\ref{eq:metropolis-accept}) to prove eq.~(\ref{eq:detailed-balance}) is a good way to appreciate the design of this acceptance probability.

Mathematically, $\pi(\bs{r})$ is the unique stationary state of the Markov chain constructed by the Metropolis method so long as $P(\bs{r}\rightarrow\bs{r}')$ is ergodic. That is, there is finite probability of reaching any state $\bs{r}'$ starting from any state $\bs{r}$ using $P$.
In practice, however, a simulation can be stuck in a meta-stable state for its entire duration, for example, due to a bad initial condition. Careful monitoring and checking of convergence is a must in any serious Monte Carlo simulation.

\section{Quantum Monte Carlo}

%A typical introduction to quantum Monte Carlo (QMC) starts with the oldest and simplest method variation Monte Carlo (VMC), then work its way to diffusion Monte Carlo (DMC) and path integral Monte Carlo.
I will start with the general, albeit somewhat complicated, path integral Monte Carlo (PIMC) method, because it rigorously takes temperature into account and connects well with Classical Monte Carlo. Then, I will describe ground-state methods as limits and efficiency tricks to specialize the path integral method to the ground state. While contrary to the historic progression of these methods, I find this perspective helpful for relating the methods and visualizing them in their respective niches.

\subsection{Path Integral Monte Carlo (PIMC)}
The quantum partition function for the canonical ensemble needs to trace over discrete N-particle eigenstates, rather than 2N 3-dimensional variables as in eq.~(\ref{eq:classical-nvt-part})
\begin{align}
Z\equiv \text{Tr}(e^{-H/k_BT})=\text{Tr}\left(
\sum\limits_{i=1}^{\infty} e^{-E_i/k_BT}\ket{\Psi_i}\bra{\Psi_i}
\right),
\end{align}
where $E_i$ and $\ket{\Psi_i}$ are the eigenvalues and eigenstates of the hamiltonian. To make contact with Classical mechanics, we put the density matrix (DM) for distinguishable particles in position basis (first quantization)
\begin{align}
\rho_D(\bs{r}, \bs{r}'; \beta) \equiv \braket{r|e^{-\beta H}|r'},
\end{align}
where $\beta\equiv \frac{1}{k_B T}$. 
Then the partition function becomes
\begin{align} \label{eq:quantum-nvt-zd}
Z(\beta) = \int d\bs{r} \rho_D(\bs{r},\bs{r};\beta),
\end{align}
which can be exactly factorized into two pieces
\begin{align}
Z(\beta) = \int d\bs{r}d\bs{r}' \rho_D(\bs{r},\bs{r};\tau)\rho_D(\bs{r},\bs{r};\beta-\tau).
\end{align}
This factorization can be repeated until the temperature becomes high enough ($\tau\rightarrow0$) that a semi-Classical approximation to $\rho_D(\bs{r},\bs{r}';\tau)$ is accurate. Given translation symmetry along imaginary time, $\beta$ is typically broken down into $M$ equal-length pieces.
For $N$ non-relativistic particles each having mass $m$, $\rho_D$ can be calculated as an integral over a discretized ``path'' of particle coordinates $\{\bs{r}_m\}$
\begin{align} \label{eq:pimc-rhod}
\rho_D(\bs{r}_0,\bs{r}_M;\beta) = \lim\limits_{M\rightarrow\infty} \int d\bs{r}_1\dots d\bs{r}_{M-1}
(4\pi\lambda\tau)^{-dNM/2}\exp\left(
-\sum\limits_{m=1}^M \left[
\dfrac{(\bs{r}_{m-1}-\bs{r}_m)^2}{4\lambda\tau} + \tau V(\bs{r}_m)
\right]
\right),
\end{align}
where ``quantumness'' $\lambda\equiv\dfrac{\hbar^2}{2m}$, imaginary time step $\tau=\beta/M$, $d$ is the number of spatial dimensions. Thus, the partition function eq.~(\ref{eq:quantum-nvt-zd}) becomes an integral of a product of high-temperature DMs over all closed paths
\begin{align} \label{eq:quantum-nvt-zd-pi}
Z=\lim\limits_{M\rightarrow\infty} \int d\bs{r} d\bs{r}_1\dots d\bs{r}_{M-1}
\rho_D(\bs{r},\bs{r}_1;\tau)\rho_D(\bs{r}_1,\bs{r}_2;\tau)\dots\rho_D(\bs{r}_{M-1},\bs{r};\tau).
\end{align}
Each closed path can be visualized as a collection of ring polymers, one for each particle. The linear extension of a ring polymer is proportional to the particle's de Broglie wavelength $\Lambda=\sqrt{4\pi\lambda\beta}$ eq.~(\ref{eq:debroglie}).
For distinguishable particles, the integral needed to evaluate the quantum partition function eq.~(\ref{eq:quantum-nvt-zd-pi}) poses no essential difficult to a Monte Carlo method when compared with its Classical counterpart eq.~(\ref{eq:classical-nvt-part-v}). One simply has to integrate $M$ Classical systems, which are coupled by the spring-like kinetic energy term in eq.~(\ref{eq:quantum-nvt-zd}).
% a technical difficult for bosons -> permutation moves
However, if the particles are identical bosons (fermions pose an essential problem, see Sec.~\ref{sec:fermion-sign-problem}), then one has to consider particle permutations along the path
\begin{align}
\rho_B(\bs{r}_0,\bs{r}_M;\beta) = \frac{1}{N!}\sum\limits_{\mathcal{P}} \rho_D(\bs{r}_0, \mathcal{P}\bs{r}_M;\beta),
\end{align}
where $\mathcal{P}\bs{r}_M$ contains the same $N$ coordinates as $\bs{r}_M$, but with the particles relabeled. This permutation can happen via any number of 1-, 2-, and upto $N$-particle exchanges between adjacent time slices along the path. Thus, the state space of bosonic path integral is much larger than that of Boltzmannic path integral. Efficient sampling of permuting paths is a significant technical challenge. Fortunately, no uncontrolled approximation has been introduced and exact simulations are possible for both Bolzmannons and bosons via the Monte Carlo method.

\subsection{Variation Path Integral a.k.a. Reptation Monte Carlo}
% ground-state path integral (VPI) -> RMC
% i.e. use a trial wavefunction as link action
The ground state is costly to study using the path integral formalism presented so far, because a large number of time slices have to be included to approximate $\beta\rightarrow\infty$. Fortunately, one can still efficiently study the ground state with the help of a trial wave function $\ket{\Psi_T}$, so long as it is non-negative. The ground-state ``partition'' function has only one term
\begin{align}
Z_0 = \lim\limits_{\beta\rightarrow\infty} \braket{\Psi_0|e^{-\beta H}|\Psi_0},
\end{align}
where $\ket{\Psi_0}$ is the ground state of the hamiltonian $H$.
For sufficiently large $\beta$, any trial wave function not orthogonal to the ground state $\braket{\Psi_T|\Psi_0}\neq0$ will be projected to the ground state by $e^{-\beta H}$, so
\begin{align} \label{eq:rmc-z0}
Z_0 = \lim\limits_{\beta\rightarrow\infty}\braket{\Psi_T|e^{-\frac{\beta}{2} H}e^{-\frac{\beta}{2} H}|\Psi_T} \approx \braket{\Psi_T|e^{-\beta_e H}e^{-\beta_e H}|\Psi_T},
\end{align}
for some $\beta_e$ large enough to be considered ``equilibrated''. Performing path discretization as before
\begin{align} \label{eq:pimc-vpi-z0}
Z_0 = \lim\limits_{M\rightarrow\infty} \int d\bs{r}_{-M}\dots d\bs{r}_0\dots d\bs{r}_{M}
\Psi_T^*(\bs{r}_{-M})\rho(\bs{r}_{-M},\bs{r}_{-M+1};\tau)\dots\rho(\bs{r}_{M-1},\bs{r}_M;\tau)\Psi_T(\bs{r}_M),
\end{align}
where $\tau=\beta_e/M$. $\beta_e$ can be small if $\ket{\Psi_T}$ is a good approximate to the ground state $\ket{\Psi_0}$. In this sense, $\ket{\Psi_T}\bra{\Psi_T}$ plays the role of a low-temperature density matrix to quickly close a long path, although its temperature is ill-defined. No permutation needs to be sampled because quantum statistics are encoded in the trial wave function. However, translation symmetry along imaginary time is broken. The 2M+1 time slices each sample a different probability distribution. Observables that do not commute with the hamiltonian are unbiased only when evaluated on the middle slice $\bs{r}_0$. The trial wave functions at the ends and the DMs in the middle of eq.~(\ref{eq:pimc-vpi-z0}) must all be non-negative for the integrand to be interpreted as a probability distribution for the paths $\{\bs{r}_{-M},\dots,\bs{r}_M\}$. This path is, in general, open ($\bs{r}_{-M}\neq\bs{r}_M$) and can be visualized as a ``reptile''. This method was first name variational path integral (VPI), but then popularized as reptation Monte Carlo (RMC). While the RMC method can be efficient, it still requires all $M$ Classical systems to be stored in memory at one time and intelligent Monte Carlo moves to change the reptile without ergodicity problems. This makes RMC much more troublesome to implement than Classical Monte Carlo or molecular dynamics.

\subsection{Diffusion Monte Carlo}
The diffusion Monte Carlo (DMC) method can be viewed as a simplification of RMC.
When calculating a ground-state observable using eq.~(\ref{eq:rmc-z0}), the \emph{pure estimator}
\begin{align} \label{eq:dmc-opure}
\braket{\hat{O}}_p \equiv \braket{\Psi_T|e^{-\beta_e H}\hat{O}e^{-\beta_e H}|\Psi_T} \approx \braket{\Psi_0|\hat{O}|\Psi_0}
\end{align}
is an unbiased ground-state estimate of $\hat{O}$ whether it commutes with the hamiltonian or not. We can forgo the pure estimator for a simpler algorithm. Consider the \emph{mixed estimator}
\begin{align} \label{eq:dmc-omixed}
\braket{\hat{O}}_m \equiv \braket{\Psi_T|\hat{O}e^{-\beta_e H}|\Psi_T}\approx\braket{\Psi_T|\hat{O}|\Psi_0}.
\end{align}
Equation~(\ref{eq:dmc-omixed}) has the advantage that the operator can be immediately applied to a trial wave function, which is known at the beginning of the calculation. Further, the $\Psi_0$ on the r.h.s. can be interpreted as being propagated from $\Psi_T$ using the \emph{imaginary-time propagator}
\begin{align}
\hat{U}(t) = e^{-t H}.
\end{align}
For any $t>\beta_e$, the observable value eq.~(\ref{eq:dmc-omixed}) should be stationary. The algorithm as described so far is similar to Classical molecular dynamics. One starts with a trial wave function $t=0$ and propagates it along imaginary time. After some initial equilibration period, the mixed estimator becomes stationary. One then runs for ``longer'' and accumulate statistics.

%For non-relativistic particles, $\nabla^2$ in the kinetic energy operator turns into a Green function for diffusion $e^{-t\nabla^2}$.
For identical non-relativistic particles having mass $m$, $\hat{U}$ in coordinate basis is the Green function for imaginary-time Schr\"odinger equation
\begin{align}
G(\bs{r}\leftarrow\bs{r}';t) = \braket{\bs{r}|\hat{U}(t)|\bs{r}'} =  \braket{\bs{r}|e^{-t(\lambda \nabla^2+V)}|\bs{r}'} = \lim\limits_{t\rightarrow 0}
\left(
(4\pi\lambda\tau)^{-dN/2}e^{-\dfrac{(\bs{r}-\bs{r}')^2}{4\lambda\tau}}
\right)
\left(
e^{-tV(\bs{r})}
\right). \label{eq:dmc-green}
\end{align}
The two terms in eq.~(\ref{eq:dmc-green}) are the Green function for diffusion and weight accumulation.
The quantumness $\lambda=\frac{\hbar^2}{2m}$ of the particle determines its diffusion constant in imaginary time. Lighter particles diffuse ``faster''. One can, in principle, start with any Classical system $\bs{r}$, apply the Green functions repeatedly to update $\bs{r}$, and eventually end up sampling the mixed distribution $\braket{\Psi_T|\Psi_0}$.

While eq.~(\ref{eq:dmc-omixed})-(\ref{eq:dmc-green}) contain the main idea behind the DMC method, they do not result in a practical algorithm. The weight of the Classical system due to the potential term goes to zero or infinity exponentially fast as the simulation progresses and whenever two charged particles coalesce. For a stable algorithm, one can modify the Green function eq.~(\ref{eq:dmc-green}) to more directly sample the mixed distribution
\begin{align}
f(\bs{r},t) \equiv \Psi_T^*(\bs{r}) e^{-t(H-E_T)}\Psi_T(\bs{r}) \underset{t\rightarrow\infty}{=} \Psi_T^*(\bs{r})\Psi_0(\bs{r}),
\end{align}
where a trial energy $E_T$ is introduced to control the potential term.
Substitute $\Psi_T^{-1}f$ in place of $\Psi$ into the imaginary-time Schr\"odinger equation $-\partial_t \Psi = H\Psi$, where $H=-\lambda\nabla^2+V$, we have
\begin{align} \label{eq:dmc-dfdt}
-\partial_t f = \Psi_T H \Psi_T^{-1} f \Rightarrow -\partial_t f=-\lambda\bs{\nabla}\cdot(\bs{\nabla}-\bs{v})f+(E_L-E_T)f,
\end{align}
% derivation is tricky! Remember \nabla\cdot(f\nabla\psi/\psi)
where the local energy $E_L\equiv \dfrac{H\Psi_T}{\Psi_T}$ and the drift vector $\bs{v}\equiv2\Psi_T^{-1}\bs{\nabla}\Psi_T=\bs{\nabla}\ln\Psi_T^2$.
After this ``important-sampling transformation'', the Green function eq.~(\ref{eq:dmc-green}) is now modified to have three contributing processes: diffusion, drift, and weighting. The initial diffusion process becomes a drift-diffusion process guided by the trial wave function. Further, the weighting by the bare potential energy becomes weighting by the local energy. Given suitably designed trial wave function, $E_L$ can be made continuous, even if the original potential $V$ contains divergences, e.g., the Coulomb interaction.
In practice, the mixed distribution is approximated by an ensemble of walkers
\begin{align}
f(\bs{r},t) \approx \sum\limits_{i=1}^{N_w} \delta(\bs{r}-\bs{r}_i),
\end{align}
and the trial energy $E_T$ is adjusted every so often to keep the population of walkers $N_w$ from explosion and distinction. Equation~(\ref{eq:dmc-dfdt}) defines the DMC algorithm.
%When viewed in a vacuum, the DMC method can be derived simply as a stochastic implementation of the power method in linear algebra.

For bosons and Bolzmannons, DMC gives the exact ground-state energy of $H$ in the limit of infinitesimal time step and uncontrolled walker population. Observables that do not commute with the hamiltonian will suffer a mixed-estimator error, which diminishes as the trial wave function is improved to have more overlap with the ground state.

\subsection{Variational Monte Carlo}
Variational Monte Carlo (VMC) can be viewed as a limit of DMC at zero projection time. I define VMC as a Monte Carlo algorithm that calculates the expectation value of an operator using a fixed trial wave function $\Psi_T$
\begin{align} \label{eq:vmc}
\braket{\hat{O}} = \braket{\Psi_T|\hat{O}|\Psi_T}.
\end{align}
The optimization of any parameters in the trial wave function will be referred to as variational optimization.
For a local observable, eq.~(\ref{eq:vmc}) becomes an integral over the $3N$-dimensional particle coordinates
\begin{align}
\braket{O} = \int d\bs{r} \dfrac{O(\bs{r})\vert\Psi_T(\bs{r})\vert^2}{\braket{\Psi_T|\Psi_T}},
\end{align}
which is easily evaluated by sampling $\bs{r}$ from the probability distribution
\begin{align}
P(\bs{r}) = \dfrac{\vert\Psi_T(\bs{r})\vert^2}{\braket{\Psi_T|\Psi_T}},
\end{align}
and accumulating $O(\bs{r})$. How does one sample a generic probability distribution like $P(\bs{r})$? One can use the Metropolis algorithm to devise a Markov chain with $P(\bs{r})$ being the stationary distribution. Alternatively, $P(\bs{r})$ can be set to be the stationary distribution of a dynamical process, e.g., Fokker-Planck dynamics.

Suppose we wish an isotropic diffusion process governed by
\begin{align} \label{eq:vmc-fokker-planck}
\dfrac{\partial f}{\partial t} = \sum\limits_{i=1}^N \lambda\dfrac{\partial}{\partial\bs{x}_i}\left(
\dfrac{\partial}{\partial\bs{x}_i} -\bs{v}_i(\bs{r})
\right)f,
\end{align}
to have $P(\bs{r})$ as its stationary distribution
\begin{align}
\lim\limits_{t\rightarrow\infty} f(\bs{r},t) = P(\bs{r}) \propto \vert\Psi_T\vert^2.
\end{align}
We can set each term in sum of the r.h.s. of eq.~(\ref{eq:vmc-fokker-planck}) to vanish
\begin{align}
\nabla_i^2 f = f\bs{\nabla}_i\cdot\bs{v}_i + \bs{v}_i\cdot\bs{\nabla}_if,
\end{align}
which gives the drift vector
\begin{align} \label{eq:vmc-drift}
\bs{v}_i = \dfrac{\bs{\nabla}_if}{f} = 2\dfrac{\bs{\nabla}_i\Psi_T}{\Psi_T}.
\end{align}
The drift vector $\bs{v}$ pushes a walker towards peaks of $P(\bs{r})$, making the sampling process more efficient than a generic Metropolis Monte Carlo move that does not use information from the trial wave function.
In fact, no accept/reject procedure is needed.
The correct stationary distribution $P(\bs{r})$ will be reached so long as the time step is small enough to accurately approximate the Green function for each step.
The Green function for the Fokker-Planck dynamics eq.~(\ref{eq:vmc-fokker-planck}) is a drift-diffusion operator. The Langevin equation needed to solve eq.~(\ref{eq:vmc-fokker-planck}) is
\begin{align}
\dfrac{\partial\bs{r}(t)}{\partial t} = \lambda \bs{v}(\bs{r}(t)) + \bs{\eta},
\end{align}
where $\bs{\eta}$ is a multidimensional Gaussian with a mean of zero and a variance of $2\lambda$. In this light, the VMC algorithm is more akin to molecular dynamics than Monte Carlo. However, the most efficient algorithm is obtained when the Fokker-Planck formulation is combined with Metropolis Monte Carlo. By introducing a metropolis accept/reject procedure at each step of the Fokker-Planck dynamics, the time step bias is eliminated because detailed balance is enforced to sample $\vert\Psi_T\vert^2$. Another way to view this is that Fokker-Planck dynamics is used to construct efficient drift-diffusion moves for an exact Monte Carlo method.

Equation~(\ref{eq:vmc-fokker-planck}) defines an efficient implementation of the VMC algorithm. Interestingly, the governing equation of DMC eq.~(\ref{eq:dmc-dfdt}) without the branching term is identical to that of VMC eq.~(\ref{eq:vmc-fokker-planck}) given the drift vector eq.~(\ref{eq:vmc-drift}).
This implies that the drift-diffusion term in the DMC Green function performs sampling only. The local energy term in eq.~(\ref{eq:dmc-dfdt}) is responsible for imaginary-time projection of the trial wave function.
%Variational Monte Carlo is the bread and butter of QMC methods.

\subsection{Fermion Sign Problem} \label{sec:fermion-sign-problem}
% sign problem for fermions
An essential difficult arises when one applies the path integral formalism to fermions. Even- and odd-permutations contribute to the fermion DM with opposite signs
\begin{align}
\rho_F(\bs{r}_0,\bs{r}_M;\beta) = \frac{1}{N!}\sum\limits_{\mathcal{P}} (-1)^{\mathcal{P}} \rho_D(\bs{r}_0, \mathcal{P}\bs{r}_M;\beta).
\end{align}
$\rho_F$ is no longer positive definite and cannot be interpreted as a probability distribution to be sampled by Monte Carlo. The canonical work-around is to sample the absolute value of the fermionic DM, which is the bosonic DM, and keep the sign as an observable. In this way, a fermionic observable is calculated as the ratio between a signful bosonic observable and the average bosonic sign
\begin{align} \label{eq:pimc-of}
\braket{\hat{O}}_F \equiv \dfrac{\Tr{\hat{O}e^{-\beta H}}_F}{\Tr{e^{-\beta H}}_F}=
\dfrac{\Tr{\hat{O}\hat{\sigma}e^{-\beta H}}_B}{\Tr{\hat{\sigma} e^{-\beta H}}_B}=
\dfrac{\Tr{\hat{O}\hat{\sigma}e^{-\beta H}}_B/Z_B}{\Tr{\hat{\sigma} e^{-\beta H}}_B/Z_B}=\dfrac{\braket{\hat{O}\hat{\sigma}}_B}{ \braket{\hat{\sigma}}_B }.
\end{align}
While mathematically exact, this leads to the well-known fermion sign problem, where the denominator in eq.~(\ref{eq:pimc-of}), the average bosonic sign, goes to zero exponentially fast as system size $N$ and inverse temperature $\beta$ are increased.
To see this, consider the total free energies of $N$ bosons vs. $N$ fermions governed by the same hamiltonian $H$. The bosonic average sign can be written as an exponential of the free energy difference
\begin{align} \label{eq:pimc-avg-sign}
\braket{\hat{\sigma}}_B = \dfrac{Z_F}{Z_B} = \dfrac{e^{-\beta F_F}}{e^{-\beta F_B}} = e^{-\beta (F_F-F_B)}.
\end{align}
Since the total free energy is extensive, the exponent in eq.~(\ref{eq:pimc-avg-sign}) is proportional to $\beta N$.
At zero Kelvin, all permutations are equally likely and the average sign is exactly zero. The sign problem can be absent in a particular system, for example due to particle-hole symmetry in a half-filled Hubbard model, and can be alleviated at finite-temperature. However, no known polynomial-scaling algorithm can solve the sign problem in general.

\begin{comment}
Minus natural logarithm of the DM is defined to be the ``action''
\begin{align}
S\equiv-\ln \rho,
\end{align}
and the exponent in eq.~(\ref{eq:pimc-rhod}) is the so-called primitive approximation to the action, which slowly becomes exact as time step goes to zero $\tau\rightarrow0$. Faster time-step convergence can be achieved using better approximation to the action.
\end{comment}

\begin{comment}
\begin{table}[h]
\centering
\begin{tabular}{cccccc}
\toprule
     & Temperature & Classical & Quantum & Quantization & Sign Problem \\
\midrule
PIMC &     any     &   yes     &   yes   & first & $\braket{\sigma}\propto \exp\left[ -\beta N (F_f-F_b) \right]$ \\
DMC  &    zero     &    no     &   yes   & first & $\braket{\sigma}\propto \exp\left[ -\beta N (F_f-F_T) \right]$ \\
FP-DMC & zero & no & yes & first & no \\
VMC & low & no & yes & first & no \\
AFQMC & low & no & yes & second & ? \\
\bottomrule
\end{tabular}
\end{table}
\end{comment}